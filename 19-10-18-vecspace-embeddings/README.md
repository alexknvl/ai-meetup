# Vector Space Embedding Models

Agenda:
* Word Embeddings and its properties (some standard examples)
* Touched on probabilistic programming.
* Troubles with high dimensions
  * All distances are the same
  * Gaussian distributions have most density in a thin shell
  * Euclidian metric breaking down
  * A demo with points randomly generated in an `D`-dimensional cube
  * And cosine similarity not
* Mathematical ideas behind Word2Vec
* Application demo: semantic search
* Knowledge Bases basics
* Node2vec
* Embedding nodes, node types, and edge types
* Gensim demo

## Data

* GloVe vector data - https://nlp.stanford.edu/projects/glove/ (more speicifically you will need [this file](http://nlp.stanford.edu/data/glove.6B.zip))
* WHAD Data (the KB we were looking at) - http://alexknvl.com/whad-data.zip
